{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch and neural network imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as utils\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "baselines.py: contains all network structure definition\n",
    "including layers definition and forward pass function definition\n",
    "\"\"\"\n",
    "\n",
    "# set the randomness to keep reproducible results\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# input size to mlp network\n",
    "mlp_input_size = 784 # img_size = (28,28) --> 28*28=784 in total\n",
    "# final output size of mlp network (output layer)\n",
    "mlp_output_size = 10 # number of output classes range [0,9]\n",
    "# width of hidden layer\n",
    "mlp_hidden_size = 10\n",
    "\n",
    "class BaselineMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        A multilayer perceptron model\n",
    "        Consists of one hidden layer and 1 output layer (all fully connected)\n",
    "        \"\"\"\n",
    "        super(BaselineMLP, self).__init__()\n",
    "        # a fully connected layer from input layer to hidden layer\n",
    "        # mlp_input_size denotes how many input neurons\n",
    "        # mlp_hiddent_size denotes how many hidden neurons\n",
    "        self.fc1 = nn.Linear(mlp_input_size, mlp_hidden_size)\n",
    "        self.fc1_5 = nn.Linear(mlp_hidden_size, int(mlp_hidden_size/2))\n",
    "        self.fc2 = nn.Linear(int(mlp_hidden_size/2), mlp_output_size)      \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Pass the batch of images through each layer of the network, applying \n",
    "        logistic activation function after hidden layer.\n",
    "        \"\"\"\n",
    "        # pass X from input layer to hidden layer\n",
    "        out = self.fc1(X)\n",
    "        # apply an activation function to the output of hidden layer\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1_5(out)\n",
    "        out = self.relu(out)\n",
    "        # pass output from hidden layer to output layer\n",
    "        out = self.fc2(out)\n",
    "        # return the feed forward output\n",
    "        return out\n",
    "\n",
    "\n",
    "class BaselineCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        A basic convolutional neural network model for baseline comparison.\n",
    "        Consists of one Conv2d layer, followed by 1 fully-connected (FC) layer:\n",
    "        conv1 -> fc1 (outputs)\n",
    "        \"\"\"\n",
    "        super(BaselineCNN, self).__init__()\n",
    "        # define different layers\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=2), #input, output, size of filter, etc\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(int(10*((32-5+1)/1)**2), mlp_output_size),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Pass the batch of images through each layer of the network, applying \n",
    "        non-linearities after each layer.\n",
    "        \n",
    "        Parameters: X --- an input batch of images\n",
    "        Returns:    out --- the output of the network\n",
    "        \"\"\"\n",
    "        # define the forward function\n",
    "        out = self.conv_layers(X)\n",
    "        activations = out\n",
    "        out = out.view(-1, int(10*((32-5+1)/1)**2))\n",
    "        out = self.fc_layers(out)\n",
    "        return out, activations\n",
    "\n",
    "    \"\"\"\n",
    "    Count the number of flattened features to be passed to fully connected layers\n",
    "    Parameters: inputs --- 4-dimensional [batch x num_channels x conv width x conv height]\n",
    "                            output from the last conv layer\n",
    "    Return: num_features --- total number of flattened features for the last layer\n",
    "    \"\"\"\n",
    "    def num_fc_features(self, inputs):\n",
    "        \n",
    "        # Get the dimensions of the layers excluding the batch number\n",
    "        size = inputs.size()[1:]\n",
    "        # Track the number of features\n",
    "        num_features = 1\n",
    "        \n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        \n",
    "        return num_features\n",
    "\n",
    "class my_nn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(my_nn,self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=0),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(10, 10, kernel_size=5, stride=1, padding=0), # 0 input filters matches 10 output filters of the previous conv layer\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(int(10*((12 - (5-1))/2)**2), 16), # the W & H of the feature maps (output) of the 1st Conv. layer is (28-(5-1))/2) = 12\n",
    "            nn.Linear(16, mlp_output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self,X):\n",
    "        out = self.conv_layers(X)\n",
    "        activations = out\n",
    "        out = out.view(-1, int(10*((12-5+1)/2)**2))\n",
    "        out = self.fc_layers(out)\n",
    "        return out, activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter = 50\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "\n",
    "\"\"\"\n",
    "Read data from the specified training, validation and test data files.\n",
    "We are using the whole image, not creating other features now\n",
    "\"\"\"\n",
    "def read_data(trainFile, valFile, testFile):\n",
    "    # train, validation, and test data loader\n",
    "    data_loaders = []\n",
    "\n",
    "    # read training, test, and validation data\n",
    "    for file in [trainFile, valFile, testFile]:\n",
    "        # read data\n",
    "        data = np.loadtxt(file)\n",
    "        # digit images\n",
    "        imgs = torch.tensor(data[:,:-1]).float()\n",
    "        # divide each image by its maximum pixel value for numerical stability\n",
    "        imgs = imgs / torch.max(imgs,dim=1).values[:,None]\n",
    "\n",
    "        # labels for each image\n",
    "        labels = torch.tensor(data[:,-1]).long()\n",
    "\n",
    "        # if using CNN model, reshape each image:\n",
    "        # [batch x num_channel x image width x image height]\n",
    "        if not use_mlp:\n",
    "            imgs = imgs.view(-1,1,28,28)\n",
    "\n",
    "        # create dataset and dataloader, a container to efficiently load data in batches\n",
    "        dataset = utils.TensorDataset(imgs,labels)\n",
    "        dataloader = utils.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        data_loaders.append(dataloader)\n",
    "    \n",
    "    return data_loaders[0], data_loaders[1], data_loaders[2]\n",
    "\n",
    "\"\"\"\n",
    "Train Multilayer Perceptron (MLP)\n",
    "Initialize MLP model --> define loss function --> define optimizer\n",
    "--> train model with num_iter epochs --> pick the best model and return\n",
    "    - Parameters:   train_loader --- the train dataloader\n",
    "                    val_loader --- the validation dataloader\n",
    "    - Return:       net --- the best trained MLP network with the lowest validation loss\n",
    "                    avg_train_loss --- a list of averaged training loss of length num_iter\n",
    "                    avg_val_loss --- a list of averaged validation loss of length num_iter\n",
    "\"\"\"\n",
    "def trainMLP(train_loader,val_loader):\n",
    "    # average training loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_train_loss = []\n",
    "    # average validation loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_val_loss = []\n",
    "    # record the lowest validation loss, used to determine early stopping (best model)\n",
    "    best_val_score = float('inf')\n",
    "    net = BaselineMLP()\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    lamb = 1e-5\n",
    "    \n",
    "    min_val_loss = float(\"inf\")\n",
    "        \n",
    "    # define loss function\n",
    "    #       define optimizer\n",
    "    #       for each iteration, iteratively train all batches\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    for epoch in tqdm(range(num_iter)):\n",
    "        \n",
    "        epoch_train_loss = []\n",
    "        epoch_val_loss = []\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = Variable(images.view(-1,28*28))\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "         \n",
    "            if True:\n",
    "                l2_reg = torch.tensor(0.)\n",
    "                for param in net.parameters():\n",
    "                    if len(param.shape) >1:\n",
    "                        l2_reg += torch.norm(param,p='fro')\n",
    "                    else:\n",
    "                        l2_reg += torch.norm(param, p=2)\n",
    "                loss += lamb * l2_reg\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 5 == 0:\n",
    "                tqdm.write('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                             %(epoch+1, num_iter, i+1, len(train_loader), loss.item()))\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            for i in range(batch_size):\n",
    "                tr_images, tr_labels = next(iter(train_loader))\n",
    "                val_images, val_labels = next(iter(test_loader))\n",
    "\n",
    "                tr_output = net(Variable(tr_images.view(-1,28*28)))\n",
    "                val_output = net(Variable(val_images.view(-1,28*28)))\n",
    "\n",
    "                tr_loss = loss_function(tr_output, Variable(tr_labels))\n",
    "                val_loss = loss_function(val_output, Variable(val_labels))\n",
    "\n",
    "                epoch_train_loss.append(tr_loss.item())\n",
    "                epoch_val_loss.append(val_loss.item())\n",
    "                \n",
    "        \n",
    "                \n",
    "        avg_train_loss.append(np.mean(epoch_train_loss))\n",
    "        avg_val_loss.append(np.mean(epoch_val_loss))\n",
    "        \n",
    "        if np.mean(epoch_val_loss) < min_val_loss:\n",
    "            min_val_loss = np.mean(epoch_val_loss)\n",
    "            torch.save(net.state_dict(), './model.pt')\n",
    "            \n",
    "    net.load_state_dict(torch.load('./model.pt'))\n",
    "        \n",
    "    return net, avg_train_loss, avg_val_loss\n",
    "\n",
    "\"\"\"\n",
    "Train Baseline Convolutional Neural Network (CNN)\n",
    "Initialize CNN model --> define loss function --> define optimizer\n",
    "--> train model with num_iter epochs --> pick the best model and return\n",
    "    - parameters:   train_loader --- the train dataloader\n",
    "                    val_loader --- the validation dataloader\n",
    "    - return:       net --- the best trained CNN network with the lowest validation loss\n",
    "                    train_loss --- a list of training loss\n",
    "\"\"\"\n",
    "def trainCNN(train_loader,val_loader):\n",
    "    # average training loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_train_loss = []\n",
    "    # average validation loss, one value per iteration (averaged over all batches in one iteration)\n",
    "    avg_val_loss = []\n",
    "    # record the lowest validation loss, used to determine early stopping (best model)\n",
    "    best_val_score = float('inf')\n",
    "    net = my_nn()\n",
    "    #       define loss function\n",
    "    #       define optimizer\n",
    "    #       for each epoch, iteratively train all batches\n",
    "    if torch.cuda.is_available():\n",
    "        net.cuda()\n",
    "    \n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "    #optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "    \n",
    "    min_val_loss = float(\"inf\")\n",
    "    lamb = 1e-5\n",
    "    \n",
    "    for epoch in tqdm(range(num_iter)):\n",
    "        \n",
    "        epoch_train_loss = []\n",
    "        epoch_val_loss = []\n",
    "        \n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs,_ = net(images)\n",
    "            #print(images.shape,outputs.shape, labels.shape)\n",
    "            loss = loss_function(outputs, labels)\n",
    "         \n",
    "            if True:\n",
    "                l2_reg = torch.tensor(0.)\n",
    "                for param in net.parameters():\n",
    "                    if len(param.shape) >1:\n",
    "                        l2_reg += torch.norm(param,p='fro')\n",
    "                    else:\n",
    "                        l2_reg += torch.norm(param, p=2)\n",
    "                loss += lamb * l2_reg\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (i+1) % 5 == 0:\n",
    "                tqdm.write('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                             %(epoch+1, num_iter, i+1, len(train_loader), loss.item()))\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            for i in range(batch_size):\n",
    "                tr_images, tr_labels = next(iter(train_loader))\n",
    "                val_images, val_labels = next(iter(test_loader))\n",
    "\n",
    "                tr_output,_ = net(tr_images)\n",
    "                val_output,_ = net(val_images)\n",
    "\n",
    "                tr_loss = loss_function(tr_output, tr_labels)\n",
    "                val_loss = loss_function(val_output, val_labels)\n",
    "\n",
    "                epoch_train_loss.append(tr_loss.item())\n",
    "                epoch_val_loss.append(val_loss.item())\n",
    "                \n",
    "        \n",
    "                \n",
    "        avg_train_loss.append(np.mean(epoch_train_loss))\n",
    "        avg_val_loss.append(np.mean(epoch_val_loss))\n",
    "        \n",
    "        if np.mean(epoch_val_loss) < min_val_loss:\n",
    "            min_val_loss = np.mean(epoch_val_loss)\n",
    "            torch.save(net.state_dict(), './model.pt')\n",
    "            \n",
    "    net.load_state_dict(torch.load('./model.pt'))\n",
    "    \n",
    "    return net, avg_train_loss, avg_val_loss\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the model, using unseen data features \"X\" and\n",
    "corresponding labels \"y\".\n",
    "Parameters: loader --- the test loader\n",
    "            net --- the best trained network\n",
    "Return: the accuracy on test set\n",
    "\"\"\"\n",
    "def evaluate(loader, net):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    # use model to get predictions\n",
    "    for X, y in loader:\n",
    "        outputs,_ = net(X)\n",
    "        predictions = torch.argmax(outputs.data, 1)\n",
    "        \n",
    "        # total number of items in dataset\n",
    "        total += y.shape[0]\n",
    "\n",
    "        # number of correctly labeled items in dataset\n",
    "        correct += torch.sum(predictions == y)\n",
    "\n",
    "    # return fraction of correctly labeled items in dataset\n",
    "    return float(correct) / float(total)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # test CNN model\n",
    "    use_mlp = False\n",
    "\n",
    "    # load data from file\n",
    "    train_loader, val_loader, test_loader = \\\n",
    "    read_data('hw0train.txt','hw0validate.txt', 'hw0test.txt')\n",
    "\n",
    "    if use_mlp:\n",
    "        net, t_losses, v_losses = trainMLP(train_loader,val_loader)\n",
    "    else:\n",
    "        net, t_losses, v_losses = trainCNN(train_loader,val_loader)\n",
    "\n",
    "    # evaluate model on validation data\n",
    "    accuracy = evaluate(test_loader, net)\n",
    "\n",
    "    print(\"Test accuracy: {}\".format(accuracy))\n",
    "\n",
    "    # plot losses\n",
    "    plt.plot(t_losses)\n",
    "    plt.plot(v_losses)\n",
    "    plt.legend([\"training_loss\",\"validation_loss\"])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss plot\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
